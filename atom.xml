<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title>blog.joshmcarthur.com</title>
  <link href="http://blog.joshmcarthur.com/atom.xml" rel="self"/>
  <link href="http://blog.joshmcarthur.com/"/>
  <updated>2011-09-30T14:22:31+13:00</updated>
  <id>http://blog.joshmcarthur.com/</id>
  <author>
    <name>@sudojosh</name>
    
  </author>

  
  <entry>
    <title>Overriding Action Caches</title>
    <link href="http://blog.joshmcarthur.com/2011/09/30/overriding-action-caches/"/>
    <updated>2011-09-30T11:48:00+13:00</updated>
    <id>http://blog.joshmcarthur.com/2011/09/30/overriding-action-caches</id>
    <content type="html">&lt;p&gt;Recently, I have been working on a web application that is quite media rich, and is expected to run into quite a bit of traffic. I've been working on building an API for a front end system, using JSON to handle passing this data back and forth.&lt;/p&gt;

&lt;p&gt;Obviously with this amount of traffic, and the size of some of the JSON collections we were having to marshall and store via Rails, we were going to need some pretty intense caching to reduce the load on Rails, and our database server. We had to balance this need, however, with the requirement that data should be live, or close to live (i.e. around 5-10 minutes) - in particular, statistics, which are calculated on-demand for several responses.&lt;/p&gt;

&lt;p&gt;The strategy we chose to manage this balance was to use Rails' provided &lt;code&gt;caches_action&lt;/code&gt; method to cache our JSON responses, building up a cache key from certain parameters, as well as some meta-data, for example, the user's logged-in status. Because we were using memcached, we could use the &lt;code&gt;:expires_in&lt;/code&gt; option to tell the memcached store to expire the cached value after x minutes.&lt;/p&gt;

&lt;p&gt;This approach worked for a while, but we found we had a pretty major problem - while the data was cached, it went alright, but as soon as the cache expired we were having loads of users hitting a response that took way to long to build (before we optimized queries, 30+ seconds). So, we needed another fix.&lt;/p&gt;

&lt;p&gt;To fix this problem, we tried out adding some cron tasks that used curl to ping the cached URLs, to try and preload the cache so that less users would be hitting the DB. This only partially fixed the problem though, so we identified a solution that would work a little better for us.&lt;/p&gt;

&lt;p&gt;What we wanted to do was to leave our existing caching in place - aside from the expiry, it was working fine, and we didn't want to rework everything. With this in mind though, we needed a way to force a refresh of the data in the cache external from the controller. What we ended up implementing was a monkeypatch on Rails' caches_action-related methods, that allows us to pass in an &lt;code&gt;:overwrite&lt;/code&gt; option - this can be a Proc, or just a boolean - basically, when the value of &lt;code&gt;:overwrite&lt;/code&gt; is true, Rails will bypass the cached value, grab the &lt;em&gt;new value&lt;/em&gt;, and load this into the cache - effectively refreshing the value without a user having to trigger the process.&lt;/p&gt;

&lt;p&gt;Here's the monkeypatch code - have a scan through it, and I'll explain it below:&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;require 'set'

module ActionController #:nodoc:
  module Caching

    module Actions
    extend ActiveSupport::Concern

      protected
      class ActionCacheFilter #:nodoc:
        def initialize(options, &amp;amp;block)
          @cache_path, @store_options, @cache_layout =
            options.values_at(:cache_path, :store_options, :layout)
        end

        def filter(controller)
          path_options = if @cache_path.respond_to?(:call)
            controller.instance_exec(controller, &amp;amp;@cache_path)
          else
            @cache_path
          end

          cache_path = ActionCachePath.new(controller, path_options || {})
          overwrite = if @overwrite = @store_options.fetch(:overwrite, nil)
            @overwrite.respond_to?(:call) ? controller.instance_exec(controller, &amp;amp;@overwrite) : @overwrite
          else
            false
          end

          body = overwrite ? nil : controller.read_fragment(cache_path.path, @store_options)

          unless body
            controller.action_has_layout = false unless @cache_layout
            yield
            controller.action_has_layout = true
            body = controller._save_fragment(cache_path.path, @store_options)
          end

          body = controller.render_to_string(:text =&amp;gt; body, :layout =&amp;gt; true) unless @cache_layout
          controller.response_body = body
          controller.content_type = Mime[cache_path.extension || :html]
        end
      end
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;By dropping this code into &lt;code&gt;config/initializers&lt;/code&gt;, this code gets patched into the ActionController::Caching::Actions::ActionCacheFilter class, and overrides the &lt;code&gt;initalize&lt;/code&gt; and &lt;code&gt;filter&lt;/code&gt; methods to let us a) pass in an override option, and b) choose to refresh the cache if the override option is set.&lt;/p&gt;

&lt;p&gt;The filter method performs as normal until it has finished generating the cache path - at this point, it would normally return the cached response if it was there, and if it had not expired. Instead, my colleague &lt;a href=&quot;http://telos.co.nz&quot;&gt;James Moriaty&lt;/a&gt; replaced some code here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First, it retrieves the value of the &lt;code&gt;:overwrite&lt;/code&gt; option passed in to the &lt;code&gt;caches_action&lt;/code&gt; method from the &lt;code&gt;@store_options&lt;/code&gt; hash - if it's a Proc, it executes it here to get the value, otherwise assumes it's a boolean variable.&lt;/li&gt;
&lt;li&gt;If the &lt;code&gt;:overwrite&lt;/code&gt; option has not been passed in, it returns false - i.e. don't overwrite the cache.&lt;/li&gt;
&lt;li&gt;If the overwrite value is true, it sets the body to nil, so that it will be re-built. Otherwise, it does the usual and returns the cached response from Memcache.&lt;/li&gt;
&lt;li&gt;From here, it more or less goes back to the default class, rebuilding the response from the database.&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;In our application's case, we use this functionality by tweaking our cron jobs a little to pass in a particular parameter - we then added the &lt;code&gt;:overwrite&lt;/code&gt; option to our &lt;code&gt;caches_action&lt;/code&gt; methods, with a Proc that returns true if this parameter equals the correct value.&lt;/p&gt;

&lt;p&gt;So far, this solution has worked fantastically - now, hardly any of our users hit the database - instead, they are heading to memcache to grab that response, while our background cron jobs rebuild the data that will get returned to them. Using a parameter for refreshing the cache also lets us easily refresh manually for testing or to check for a value.&lt;/p&gt;

&lt;p&gt;This solution is clean, simple and easy to implement. I suggest that if you are facing similar problems, that you give it a go - it's really adaptable, and requires few changes if you are already using action caching. Full credit to James for thinking up and implementing this solution - I'm just documenting it.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Howto: Database Backup and Restore</title>
    <link href="http://blog.joshmcarthur.com/2011/09/23/howto-database-backup-and-restore/"/>
    <updated>2011-09-23T13:26:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/09/23/howto-database-backup-and-restore</id>
    <content type="html">&lt;p&gt;An inherent part of developing web applications is managing your datastores - typically, a relational database such as MySQL or PostgreSQL. Today, I'm going to quickly cover off how to backup and restore for both of these databases.&lt;/p&gt;

&lt;h2&gt;What you'll need&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Either PostgreSQL or MySQL&lt;/li&gt;
&lt;li&gt;Access to a database (preferably one with data in it)&lt;/li&gt;
&lt;/ul&gt;


&lt;h2&gt;Why this is useful to know&lt;/h2&gt;

&lt;p&gt;Lots of interactions with databases have the potential to destroy or modify data (in a bad way). When using frameworks such as Ruby on Rails, it's even easier to, say, accidently delete all of your Users (Horribly easy in DataMapper, unfortunately). It's important that before you do anything with data that's destructive, you have a backup of your database that you can restore from quickly and easily.&lt;/p&gt;

&lt;h2&gt;PostgreSQL&lt;/h2&gt;

&lt;p&gt;Postgres databases are backed up using the &lt;code&gt;pg_dump&lt;/code&gt; command - a command-line utility that comes packaged with the database server. Here's the command:&lt;/p&gt;

&lt;p&gt;``` sh&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pg_dump --no-owner -U [username] -W [database_name] &amp;gt; [file to dump to].sql.dump
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Let me explain these options and why I use them:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;--no-owner&lt;/code&gt;: By default, Postgres dumps the database with lots of SET OWNER TO statements. I like to take these out of the dump, as I'm not necessarily restoring the dump to exactly the same server with exactly the same users. Using --no-owner means that ownership statements will be excluded.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-U [username]&lt;/code&gt;: This lets you pass in the database user name your web application usually uses to connect - using this is just good practise, as it ensures that what you're dumping is exactly what the web application has.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-W&lt;/code&gt;: This option, used in conjunction with the &lt;code&gt;-U&lt;/code&gt; flag, prompts for the password when you run the command&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[database_name]&lt;/code&gt;: This is the name of the database that you want to dump&lt;/li&gt;
&lt;li&gt;&lt;code&gt;[file to dump to]&lt;/code&gt;: This is the file that the SQL script that pg_dump produces will be piped into. I normally name this file with the &lt;code&gt;.sql.dump&lt;/code&gt; extension, so that I can see it's a SQL dump straight off.&lt;/li&gt;
&lt;/ul&gt;


&lt;h4&gt;Restoring a database dump&lt;/h4&gt;

&lt;p&gt;Restoring a Postgresql dump is really easy, and involves using the standard &lt;code&gt;psql&lt;/code&gt; client to connect to the database and execute the SQL script in your dump file.&lt;/p&gt;

&lt;p&gt;First of all, make sure that you have created the database you want to load the data into. In this example, let's say I've dumped from the &lt;code&gt;facebook_production&lt;/code&gt; database to the file &lt;code&gt;facebook_production_23092011.sql.dump&lt;/code&gt;, and I want to restore into the &lt;code&gt;facebook_development&lt;/code&gt; database so that I can test out some code against some production data. I want to connect to the database using psql as the web application user, and load the dump in:&lt;/p&gt;

&lt;p&gt;``` sh&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;psql -U facebook -W facebook_development &amp;lt; facebook_production_23092011.sql.dump`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Note how I am using the opposite of the less-than symbol I used above - this basically denotes the direction of the data - it's coming &lt;em&gt;from&lt;/em&gt; the file, going &lt;em&gt;to&lt;/em&gt; the database.&lt;/p&gt;

&lt;p&gt;Upon running this commmand (with your own database, of course), you will first be prompted for your database user's password, and will then see a bunch of SQL statements being executed. Once it's completed, your database has been loaded successfully - you can jump in using psql if you'd like, and query around a bit.&lt;/p&gt;

&lt;h2&gt;MySQL&lt;/h2&gt;

&lt;p&gt;MySQL databases are backed up with the &lt;code&gt;mysqldump&lt;/code&gt; program - one I'm not as familiar with as Postgres, but I know the basics, and largely that's all you need with this type of thing. The main thing to keep in mind is that the process is the same as for PostgreSQL above - use the dump program to write the database out to a file (in the form of SQL statements), and then use the database client program &lt;code&gt;mysql&lt;/code&gt; in this case, to execute the commands in the file against the database being restored to. Here's the command to dump a MySQL file to disk:&lt;/p&gt;

&lt;p&gt;``` sh&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysqldump -U [username] -P [database_name] &amp;gt; [file to dump to].sql.dump
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;The options are more or less as I've described above, except that &lt;code&gt;-P&lt;/code&gt; is substituted for &lt;code&gt;-W&lt;/code&gt;, and I've still stuck with the &lt;code&gt;.sql.dump&lt;/code&gt; naming scheme.&lt;/p&gt;

&lt;h4&gt;Restoring a database dump&lt;/h4&gt;

&lt;p&gt;This process is almost identical to the PostgreSQL restore process. Let's stick with the same example format we already have - dumping from a database called &lt;code&gt;facebook_production&lt;/code&gt; to file &lt;code&gt;facebook_production_23092011.sql.dump&lt;/code&gt;, restoring into a database called &lt;code&gt;facebook_development&lt;/code&gt; - here's the command we need for that:&lt;/p&gt;

&lt;p&gt;``` sh&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mysql -U facebook -P facebook_development &amp;lt; facebook_production_23092011.sql.dump
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Once again, you'll be prompted for your password, but for this one you won't see the output of the SQL statements - it will take a couple of seconds, and then the program will exit. This is normal however - if you'd like to see the output of the batch load, you can add &lt;code&gt;-v -v -v&lt;/code&gt; before the &lt;code&gt;&amp;lt;&lt;/code&gt; symbol to turn verbosity to level three, otherwise you can go ahead and jump into your database and make sure everything is there.&lt;/p&gt;

&lt;h2&gt;Tips:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;If you don't have a database user account yet, on Unix and Linux you can use &lt;code&gt;sudo su postgres&lt;/code&gt; to login as the 'postgres' user - a root-like database user that gets created for you when Postgres is installed. MySQL has a root account, but it's not a system user - you are normally prompted for a root username and password when you install MySQL. If you &lt;em&gt;are&lt;/em&gt; using the Postgres user, you don't need to pass in a username or password in the above commands, but you need to remember that your restored databases will be owned by 'postgres', not you web application database user.&lt;/li&gt;
&lt;li&gt;A handy place to put database dumps that you are planning to use right away is &lt;code&gt;/tmp&lt;/code&gt; (Only on Unix and Linux). This is a directly that is writeable by everyone, that will get 'garbage collected' periodically. This is especially handy if you are logging in as the 'postgres' user, as typically this user won't have write permissions on many other directories&lt;/li&gt;
&lt;/ul&gt;

</content>
  </entry>
  
  <entry>
    <title>Introducing Blog Broadcaster</title>
    <link href="http://blog.joshmcarthur.com/2011/09/14/introducing-blog-broadcaster/"/>
    <updated>2011-09-14T19:04:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/09/14/introducing-blog-broadcaster</id>
    <content type="html">&lt;p&gt;I've just completed a Blog Broadcaster for this blog. It had a couple of interesting technical things, and I needed to test it properly, so here's this post!&lt;/p&gt;

&lt;p&gt;I recently migrated this blog from &lt;a href=&quot;http://tumblr.com&quot;&gt;Tumblr&lt;/a&gt;, and while Tumblr was pretty awesome and easy to use, it didn't have great support for blocks of code and preformatted comment, and, like &lt;a href=&quot;http://www.radiantcms.org&quot;&gt;Radiant CMS&lt;/a&gt;, it stored layouts, stylesheets, and all of that kind of thing in a database somewhere - it wasn't in source control, and making changes to it was dangerous.&lt;/p&gt;

&lt;p&gt;One thing that I immediately missed from Tumblr, however, was it's ability to post to Facebook and Twitter automatically whenever I published a post. As I don't post that often, it's really important to me that I market my blog as much as I can - like my Github profile, the content on my blog is a reflection of my knowledge and skill as a developer, and so I want to get that in front of people as much as possible - broadcasting to social networks is a great way of achieving that.&lt;/p&gt;

&lt;p&gt;With my blog on Github, I needed a way to broadcast new posts to these social networks. Github has a built-in post-receive hook to post to Twitter, but I really needed something more than that. Here's my list of requirements:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It should automatically post without me needing to do any special task&lt;/li&gt;
&lt;li&gt;It should be conditional - i.e. it shouldn't post &lt;em&gt;everytime&lt;/em&gt; I change something&lt;/li&gt;
&lt;li&gt;It should support both Facebook and Twitter&lt;/li&gt;
&lt;li&gt;It should be able to be triggered by a commit&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;What I ended up building was a Sinatra app whose sole purpose was to receive POST'ed commit information, parse it into a Facebook and Twitter post, and broadcast it. It's hosted on Heroku, and gets triggered by a Github &lt;a href=&quot;http://help.github.com/post-receive-hooks/&quot;&gt;Post-Receive Hooks&lt;/a&gt;. I did run into a couple of problems along the way - the main one was sorting out being able to post Facebook updates without being logged in, or even needing to be involved at the process at all. This wasn't too difficult, but I did need to get an access token that was long-lived, and have the ability to update this if necessary. I overcame this problem by adding some methods to my Sinatra app that will allow me to update the access token if it ever expires, or change the Facebook account used if necessary.&lt;/p&gt;

&lt;p&gt;The second problem I ran into wasn't really a problem, but it was a challenge to try and think of a nice way of doing it. Basically I needed to store the Facebook access token somewhere so that I could use it when I needed it - but I didn't have a database, and I didn't particularly want to add one just for storing a single string. Since this is running on Heroku (Bamboo stack, not Cedar), I was also on a read-only filesystem, so couldn't store it in a simple text file either. In this end, I chose to store the value in Memcache using the Heroku add-on. This still isn't necessarily a good solution, as this storage method isn't guaranteed to be persistent, however it should suit my needs - it doesn't particularly matter if I lose the access token, the application will gracefully degrade and just post to Twitter until I log in to Facebook via the app again.&lt;/p&gt;

&lt;p&gt;So, I think I've come up with a good solution. It started off as a simple broadcaster for my blog, but I think it has a lot of potential for use with any open-source project that has social networking presence - I think it's a much more elegant and flexible hook than that which Github provides, and I hope it get's a bit of use.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Select Anything From Everything with Select</title>
    <link href="http://blog.joshmcarthur.com/2011/09/09/select-anything-from-everything/"/>
    <updated>2011-09-09T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/09/09/select-anything-from-everything</id>
    <content type="html">&lt;p&gt;I was recently called upon to make a horrible select input for a Ruby on Rails project - essentially, there was this model, let's call it a Snafu, and one Snafu could share an attachment to any number of models.&lt;/p&gt;

&lt;p&gt;This select was difficult because I couldn't just have a selection of record ID's - I would have to use both the model type &lt;strong&gt;as well as&lt;/strong&gt; the model ID in order to be able to track down these records when the form was submitted. Here's how I did it:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Rendering the select &lt;/strong&gt;
First of all, we need to render a selection box for the 'New Snafu' form. This selection box should be populated by a number of model collections, keyed by an identifier that specifies both the model name and the model ID. Time for a model method, and a helper!&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def options_for_select_anything(selected = nil)
 #Make a hash of the things we want to select from
 options = {
  'Foo' =&amp;gt; Foo.active.map(&amp;amp;item_for_select_anything),
  'Bar' =&amp;gt; Bar.active.map(&amp;amp;item_for_select_anything)
 }
 #Use a Rails helper to actually get the tags
 grouped_options_for_select(options, selected)
end

def item_for_select_anything
 # Return an array of the record name and the identifier we want to use
 # The record name in this case is the display value, while the identifier
 # is the data value
 lambda { |record| [record.name, &quot;#{record.id}-#{record.class.name}&quot;] }
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Now that we have these helpers, we have a grouped collection of options, in which each option tag within the select will look something like '&lt;code&gt;&amp;lt;option value=&quot;1-Foo&quot;&amp;gt;Foo #1&amp;lt;/option&amp;gt;&lt;/code&gt;' - let's render our select.&lt;/p&gt;

&lt;p&gt;``` erb&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;% form_for @snafu do |form| %&amp;gt;
    &amp;lt;p&amp;gt;
        &amp;lt;%= form.label :item_identifier, 'Item' %&amp;gt;&amp;lt;br /&amp;gt;
        &amp;lt;%= form.select :item_identifier, options_for_select_anything %&amp;gt;
    &amp;lt;/p&amp;gt;
    &amp;lt;p&amp;gt;
        &amp;lt;%= form.submit 'Create' %&amp;gt;
    &amp;lt;/p&amp;gt;
&amp;lt;% end %&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;This is a basic form of course - your form will have all the other attributes you need, but the key thing to notice here is that we aren't trying to load against our Polymorphic 'item' association within the form - instead, we're just going to send through a 'item_identifier' parameter that we can use to &lt;em&gt;find&lt;/em&gt; the item in our model. Let's take a look at the sections we need.&lt;/p&gt;

&lt;p&gt;First of all, we need to have the Polymorphic association in our model, if you haven't already done this.&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Snafu.rb

class Snafu &amp;lt; ActiveRecord::Base
    # Snip
    belongs_to :item, :polymorphic =&amp;gt; true
    # Snip
end

# Migration
add_column :snafus, :item_id, :integer, :null =&amp;gt; false
add_column :snafus, :item_type, :string, :null =&amp;gt; false
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Next of all, we need to add an &lt;code&gt;attr_writer&lt;/code&gt; to our model - this will hold the 'item_identifier' from our form submission until we are ready to use it.&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Snafu.rb

attr_writer :item_identifier
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Finally, we need to add a &lt;code&gt;before_validation&lt;/code&gt; filter to associate the record identified by our item_identifier with our model instance:&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Snafu.rb
class Snafu &amp;lt; ActiveRecord::Base
    # Snip
    belongs_to :item, :polymorphic =&amp;gt; true
    before_validation :set_item

    attr_writer :item_identifier

    # Snip

    private

    def set_item
        if self.item_identifier
        id, model = self.item_identifier.split('-')
        self.item = Kernel.const_get(model).send(:find, id) rescue nil
    end
 end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;Let's take a look at what we've done there - really, the meat of it is in our set_item method, that gets called before validations run (so that we will have a real item set before we may need to run validations on that item). First of all, set_item checks that we have set a item_identifier - if we haven't we don't want to run into Nil exceptions! Given an item_identifier is present, we want to split our identifier (Remember, this is in the format id-class name), into two parts. Finally, we do a little Ruby magic to get the class using Kernel.const_get, and then call &lt;code&gt;find&lt;/code&gt; on it with the ID that we want. If anything goes wrong with this bit (The class not existing, for example), then we just set item to nil.&lt;/p&gt;

&lt;p&gt;There we have it then - it's a horrible situation, but I feel like it's a pretty good approach. The logic is where it should be (models and helpers), the views and controllers feel clean, and it's flexible to be reused pretty easily.&lt;/p&gt;

&lt;p&gt;As a final tweak, there's one more change you may want to make - that is setting the selected item when we return to our form. If you take a look at the helper method we defined above, you'll notice that we already support a selected option - we just need to pass this in. To do this, we want to add a method to our 'Snafu' class that will return a string of the item id and the item name concatenated with a dash - i.e., the format that our select box in the form is expecting. Go ahead and add the method now:&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Snafu.rb

def item_identifier
    # Return the owner_identifier set using the attr_writer, if it exists
    return @owner_identifier if @owner_identifier

    # Otherwise, try and build it from the current item saved against the model
    [self.item.id, self.item.class.name].join('-') if self.item.present?
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;With that method, can can just change our select input in the form to make use of this value:&lt;/p&gt;

&lt;p&gt;``` ruby&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# new.html.erb
# Snip
&amp;lt;%= form.select :item_identifier, options_for_select_anything(form.object.item_identifier) %&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;```&lt;/p&gt;

&lt;p&gt;There we are! Now when we show the form, the selected item will appear, just as we wanted.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Capistrano rvm-shell: command not found error</title>
    <link href="http://blog.joshmcarthur.com/2011/08/22/capistrano-rvm-shell-command-not-found-error/"/>
    <updated>2011-08-22T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/08/22/capistrano-rvm-shell-command-not-found-error</id>
    <content type="html">&lt;p&gt;I've just come across this problem, and I had to share it here - I can't find
anywhere else on the the Internet where the solution is specifically stated -
it's just alluded towards. If you are using RVM's Capistrano integration, you
may come across a CommandNotFoundError to do with rvm-shell not being under /
usr/local/rvm/bin (Which is exactly where it should be). Upon searching the
internet, you will find that you have to upgrade RVM (you don't), and that when
installed for a local user, RVM puts rvm-shell under ~/bin (But, you know, it's
a system-wide install). The solution is really simple - rvm-shell is under /
usr/local/bin - use &lt;code&gt;set :rvm_bin_path, &quot;/usr/local/bin&quot;&lt;/code&gt; in your deploy
script, and you're away. Clearly this is a bug with RVM putting things where it
shouldn't, but that's the way of things. And, if I sound a little short, it's
because I had to all but reinstall RVM and break everything before realizing
this.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Achievements on Coderwall</title>
    <link href="http://blog.joshmcarthur.com/2011/07/23/achievements-on-coderwall/"/>
    <updated>2011-07-23T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/07/23/achievements-on-coderwall</id>
    <content type="html">&lt;p&gt;Well, it's taken weeks for &lt;a href=&quot;http://coderwall.com&quot;&gt;Coderwall&lt;/a&gt; to finally get
it's crawler to hit my &lt;a href=&quot;https://github.com/joshmcarthur&quot;&gt;Github Profile&lt;/a&gt;, but
I've finally &lt;a href=&quot;http://coderwall.com/joshmcarthur&quot;&gt;got more badges&lt;/a&gt;. I've been
moving some old PHP stuff of mine onto Github for people to use, so that's
where I've gotten the PHP badge from. As part of my personal campaign to master
at least one other language apart from Ruby, I've also been working on some
Django tutorials (Django is a Python web framework), so have earned another
badge there. A happy accident was the walrus badge - I didn't realize I had
projects up in so many different languages. Probably next on this list might be
the 'Forked 20' achievement for my Spree extension, [spree-import-products]
(https://github.com/joshmcarthur/spree-import-products) - I'm not so sure this
is a good thing, though - the forks-to-pull-requests ratio is too low on this
project - most likely indicating that I need to work more on making the
extension easier to use for my general audience - forks without pull requests
mean that people are taking their own copies to change them for their needs,
rather than to work on bugfixes and general improvements. We'll have to see.
But... yay, more achievements! If you've got a Github account, I highly
recommend you check out Coderwall - the achievements are largely irrelevant to
any sort of reputation, but it's a really nice way of finding interesting
Github members with interesting projects.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Arbitrary Ordering in PostgreSQL when Rails + ENUM = No.</title>
    <link href="http://blog.joshmcarthur.com/2011/07/14/arbitrary-ordering-in-postgresql-when-rails-enum-no/"/>
    <updated>2011-07-14T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/07/14/arbitrary-ordering-in-postgresql-when-rails-enum-no</id>
    <content type="html">&lt;p&gt;I've recently had to do a custom sort for a work project that has required a
sort on something that is not naturally sortable correctly (For example,
alphabetical or numerical sorting). While searching for a completely different
solution, I came across &lt;a href=&quot;http://stackoverflow.com/questions/1309624/%0Asimulating-mysqls-order-by-field-in-postgresql&quot;&gt;this post&lt;/a&gt; that outlined a nice technique.
Basically, when you have a field in your Rails model with a predefined set of
possible values, you can use a CASE statement in PostgreSQL to perform the sort
in whichever order these values should appear. Here's a sample of how this
could be achieved using Rails: &lt;code&gt;Result.order(&quot;CASE &quot; + &quot;WHEN medal='gold'
THEN 1 &quot; + &quot;WHEN medal='silver' THEN 2 &quot; + &quot;WHEN medal='bronze' THEN 3 &quot; +
&quot;ELSE 4 &quot; + + &quot;END,name&quot;)&lt;/code&gt; It's messy of course - how you want to format the
SQL string is up to you, but it's a great solution when you don't have the
normal sorting capabilities of a ENUM datatype available to you.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Quick: Clear Gemset</title>
    <link href="http://blog.joshmcarthur.com/2011/07/10/quick-clear-gemset/"/>
    <updated>2011-07-10T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/07/10/quick-clear-gemset</id>
    <content type="html">&lt;p&gt;If you're finding that you have to change something fairly significant in your
bundler dependencies, it's usually a good idea to get rid of what you've got
loaded in an RVM gemset so that you don't end up with different versions of
gems fighting with each other. To do this, simply run &lt;strong&gt;&lt;code&gt;rvm gemset empty&lt;/code&gt;&lt;/strong&gt; -
it'll delete all the gems currently in your gemset, giving you a blank slate.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>The Dictionary of New Zealand Sign Language</title>
    <link href="http://blog.joshmcarthur.com/2011/06/27/the-dictionary-of-new-zealand-sign-language/"/>
    <updated>2011-06-27T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/27/the-dictionary-of-new-zealand-sign-language</id>
    <content type="html">&lt;p&gt;&lt;a href=&quot;http://nzsl.vuw.ac.nz&quot;&gt;The Dictionary of New Zealand Sign Language&lt;/a&gt; went live
on Friday - it's a project that I have worked on with &lt;a href=&quot;http://%0Awww.danielsherson.com&quot;&gt;Daniel&lt;/a&gt;, Chris and &lt;a href=&quot;http://www.linkedin.com/in/%0Ajamesarobertson&quot;&gt;James R&lt;/a&gt;, at 3Months. I attended a launch event at Victoria University
on the Friday, and it really was quite a humbling experience - this dictionary
has been the effort of a team of people for years and years - really, what
3Months has done has just been the tip of the iceberg. It really does seem like
this project has been rewarding - we've taken a comprehensive database of sign
information and images (Built with what seems to be a lot of time and effort by
&lt;a href=&quot;http://dave.moskovitz.co.nz/2011/06/24/the-online-dictionary-%0Aof-new-zealand-sign-language/&quot;&gt;Dave Moskozitz&lt;/a&gt;), and given it a public presence - hopefully,
something that everyone can use - whether it's to learn New Zealand Sign
Language, or just to learn how to finger spell names and words. I'm mostly
posting this in the hope that everyone who reads this goes to check out the
site, and to learn something of this language - give it a spin! &lt;a href=&quot;http://nzsl.vuw.ac.nz&quot;&gt;http://
nzsl.vuw.ac.nz&lt;/a&gt;&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>'Password' or 'Passphrase'</title>
    <link href="http://blog.joshmcarthur.com/2011/06/23/-password-or-passphrase/"/>
    <updated>2011-06-23T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/23/-password-or-passphrase</id>
    <content type="html">&lt;p&gt;So apparently pass phrases are the new 'secure password' - kinda the step you
get to when you finally accept that your users are going to use something like
'password' for their account password. The natural step here is to reinforce a
secure password strategy by requiring x numbers, x special characters and a
certain length - but I find this really annoying when I just want to get signed
up, and that means that other users do as well. Something I've just been
thinking about is the naming semantics of password field - labeling it
'password' immediately prompts users to think of an actual word - if they are
computer-savvy, then they might throw a symbol or number in, but most likely it
will still be based on an actual word. I wonder what would happen if you
labelled this field 'Passphrase' though? I think it is inevitable that many
users will recognize the pattern of the form rather than the labelling of the
fields and still enter their 'password', but just maybe there will be some
users who get the semantics of the label, and enter a sentence, instead of a
word. Even though there may not be special characters in that sentence, it's
still just as, if not more secure from dictionary attacks - guessing one word
is pretty easy, but it's much, much harder to guess a string of words, in the
correct order - especially if one or two of those words are obfuscated with
some special characters or numbers. Just a thought.... but interesting
nonetheless.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Rails HABTM relationships on a non-standard connection</title>
    <link href="http://blog.joshmcarthur.com/2011/06/21/rails-habtm-relationships-on-a-non-standard-connection/"/>
    <updated>2011-06-21T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/21/rails-habtm-relationships-on-a-non-standard-connection</id>
    <content type="html">&lt;p&gt;Recently, I've been implementing an admin interface for a system that I want to
make more secure than the main application. The way I've chosen to do this is
to run some models that relate solely to the admin application (Authentication
and Authorization in particular), on a different database - let's call it
'login'. This seems to be a reasonably common thing to do for security
purposes, and also for things like moving data from one database to another.
Once again though, I've been tempted into the potential nest of bugs that is
has_and_belongs_to_many - let me explain the schema first though: *
Administrators table - holds email, encrypted passwords and other data about
administrators * Roles table - holds the name of the role - used to authorizing
an administrator when performing an action. Each of these tables uses the line
&lt;code&gt;establish_connection 'login'&lt;/code&gt; to connect to a different database than the
other models - this is the secure database that I want to leave purely for the
administrative application. So, given that I had an administrator that should
be given multiple roles, and obviously each role could have many
administrators, has_and_belongs_to_many seemed the obvious candidate - I didn't
really want a model just for the association, and I would just need to write a
migration to create the join table. So, off, I went, and here's what happened:
&lt;code&gt;ERROR: relation &quot;administrators_roles&quot; does not exist&lt;/code&gt; i.e. - the
Administrator table exists, and the Role table exists, but the join table just
isn't there. The first call for me was to take a look in the database, and make
sure that the table was there - which it was - and that migrations had
definitely run correctly and the schema was correct - which they were. After
much frustration, I found &lt;a href=&quot;http://groups.google.com/group/%0Arubyonrails-talk/browse_thread/thread/7644d9e5f5c6e44a/%0A69c8cce4c39eb571?show_docid=69c8cce4c39eb571&quot;&gt;this thread&lt;/a&gt; which described the problems I
had been having - and I was vaguely satisfied to see that the problem wasn't
really my fault. It seems that in some versions of Rails, ActiveRecord's
has_and_belongs_to_many_association class doesn't respect the database
connections that the models are trying to use - instead, it uses the universal
database connection to try and look up the join table - so, what was going
wrong was that ActiveRecord was looking in the development environment's
database, when it should have been looking in the login database.
Unfortunately, short of updating your version of ActiveRecord/Rails or patching
this class, it seems that there isn't really any way of avoiding this problem -
you have to drop back to using has_many :through with a Model representing your
join table. I can, though, at least vouch that once you have done this, it does
work as expected, which, in the end, is what we want. It still feels a bit
hacky though....&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Quick: .rvmrc</title>
    <link href="http://blog.joshmcarthur.com/2011/06/21/quick-rvmrc/"/>
    <updated>2011-06-21T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/21/quick-rvmrc</id>
    <content type="html">&lt;p&gt;This post is probably something more experienced RVM users will already know,
but I wanted to post this as it's definitely my discovery of the week. When
throwing an .rvmrc file into a project, it's a nice thing to do to write the
script correctly so that it will just work for other developers (As well as
telling you what gemset you're using when you jump into the directory). In your
.rvmrc file, put something like this: &lt;code&gt;rvm use 1.9.2@gemset --create&lt;/code&gt; ...this
will attempt to use that gemset (Printing out a nice message telling you it's
using that one as it does so), and will create it if it doesn't exist.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Ubuntu: Quick ImageMagick Install</title>
    <link href="http://blog.joshmcarthur.com/2011/06/16/ubuntu-quick-imagemagick-install/"/>
    <updated>2011-06-16T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/16/ubuntu-quick-imagemagick-install</id>
    <content type="html">&lt;p&gt;[This is cross-posted from a tweet I posted a while back - I think it's a nice
bit of advice, and I wanted to store it in a more persistent form]
Installing ImageMagick is one of the things that Rails developers need to do
reasonably often when provisioning new servers - basically, if you're doing any
sort of image processing in your application (including the popularPaperclip
gem), ImageMagick is what you'll be using.
The problem is that there is a bit of a magical formula I have needed to use in
the past - if you just install ImageMagick, it will most likely not work, as it
needs to have support for different image formats you want to use compiled it
in right from the get go. Previously, I have just looked up the various
libraries I have needed (For PNG, JPEG, etc.), and then either found the
libraries in the Ubuntu package repositories or built them from source.Â 
A nice quick way of doing it though, is to use an ImageMagick meta-package in
the Ubuntu repositories named libmagick-9-dev - it is just a collection of
popular image format libraries, as well as a couple of additional utilities for
ImageMagick. You can install it on any Ubuntu system by running this command:
sudo apt-get install libmagick-9-dev
ImageMagick itself still needs to be installed, of course. The best option here
is just to build from source - packages in the repositories are horribly out of
date, and I have found Paperclip, RMagick and Minimagick all require a fairly
recent version of ImageMagick.
Building from source sounds really intimidating, but it really isn't - just
follow these steps:
First of all, download a tarball of the ImageMagick source onto your computer:
wget ftp://ftp.imagemagick.org/pub/ImageMagick/ImageMagick.tar.gz
Next, extract the tarball:
tar -xvzf ImageMagick.tar.gz
Now configure the package - note especially the end of the output (There is a
lot of output) - it tells you which Image libraries you have installed - any
with 'yes' next to them it will happily format and convert - because you've
installed the package above, all the common formats should have a 'yes' next to
them, but it's worth checking.
cd ImageMagick-[VERSION] (VERSION will be a series of numbers like '6.7.0-8')
./configure
Now all the hard work (By you) is done - you just need to compile the packages:
make &amp;amp;&amp;amp; sudo make install
All done! - ImageMagick should be all installed. To check, run the command
which identify, and check it returns a path to the 'identify' command.
Note: If you have trouble compiling, make sure Ubunutu's build tools are
installed: sudo apt-get install build-essential&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Integration tests with Devise and RSpec</title>
    <link href="http://blog.joshmcarthur.com/2011/06/11/integration-tests-with-devise-and-rspec/"/>
    <updated>2011-06-11T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/11/integration-tests-with-devise-and-rspec</id>
    <content type="html">&lt;p&gt;RSpec 2 has supported integration tests for a while now, and I've chosen to use
these for a project I'm working on at the moment instead of Cucumber (I don't
feel that I need the verbosity andÂ English-like structure Cucumber provides
given that it a more complex process to write tests).
A bit of a problem I've come across recently is how to get a Devise user signed
in to your application in your tests, given that integration tests don't really
give you any access to either the session or the controller (This rules out
manually setting ID's in the session, or stubbing out current_user. As it turns
out, the implementation of it is pretty simple, but I did have to do a bit of
browsing and piece a few bits together to work out a nice way of doing it.
Here is the code you can use (You would normally place this within a before(:
each) filter in your routes spec (Which is what an integration test in RSpec is
called):
[At top of spec file, after require 'spec_helper'
include Warden::Test::Helpers
[In a before(:each) block]
@user = Factory.create(:user)
@user.confirm!
login_as @user, :scope =&gt; :user
Now, what is this doing? Well, first of all, you include some test helpers that
Warden (Which devise back-ends onto), provides. I tried out using Devise's
Devise::TestHelpers here, but it looks like Devise haven't really designed
their helpers with integration tests in mind - they didn't really work.Â 
Within our before(:each) block, it now gets pretty simple. We create a User,
using Factory Girl (This part of the implementation doesn't really matter, you
can use fixtures if you prefer, or even a plain old User.create.
Next, we confirm the user. This isn't necessary if your users haven't been
marked as :confirmable in your User model, but obviously our new user needs to
be confirmed and active in order to log in.
Last of all, we use a helper method Warden's test helpers has provided us to
log in the user, which sets us up for any more requests we need to make.
Have fun speccing nicely with Devise/Warden and RSpec!&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Quick: Get random record efficiently in Rails</title>
    <link href="http://blog.joshmcarthur.com/2011/06/07/quick-get-random-record-efficiently-in-rails/"/>
    <updated>2011-06-07T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/06/07/quick-get-random-record-efficiently-in-rails</id>
    <content type="html">&lt;p&gt;You could use SQL's random function (RAND() or RANDOM() depending on database
engine) - but this isn't database agnostic, so isn't really very quick.
Instead you can use @nzkoz's suggested method:
Widget.first(:offset =&gt; Widget.count)
.... the count() method is fast, and the first() method will limit it to the
first result in the SQL as well.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>ImageMagick: Cropping then Resizing a PNG</title>
    <link href="http://blog.joshmcarthur.com/2011/05/06/imagemagick-cropping-then-resizing-a-png/"/>
    <updated>2011-05-06T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/05/06/imagemagick-cropping-then-resizing-a-png</id>
    <content type="html">&lt;p&gt;I've been working on an image processor class for work, and recently ran into
this issue. I thought I would post it up here as normally I need to be quite
desperate before I start trawling through email mirrors - hopefully somebody
comes across this post first.
If you use ImageMagick (in particular, in conjunction with MiniMagick), then
you may come across this issue, and there is actually a quick fix to it. The
issue itself is as follows: my image processor retrieves an image from an
online source, but the image has a 1 or 2px border, and is thousands of pixels
wide - too wide for web use. I therefore wrote this class to first crop the
border off the image, and then resize it.
If you do actually do this though, there is an important step that needs to go
in-between the cropping and the resizing. If you won't do this, you will
basically get a PNG layer that is offset from the image itself - i.e. some or
all of the Â actual image content is not visible. This happens because when the
image is cropped, the origin of the image changes. It needs to be reset back to
coordinates 0, 0 in order to not offset the layer itself when the image is
resized.
Here's how to do it.Â 
For Ruby/Minimagick:
image.set(&quot;page&quot;, &quot;#{image['width']}x#{image['height']}+0+0&quot;)
For ImageMagick directly (i.e. in console):
convert [image sequence]: -set page [width]x[height]+0+0
Simple! The image should save correctly.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Using setInterval to handle scroll() events</title>
    <link href="http://blog.joshmcarthur.com/2011/04/12/using-setinterval-to-handle-scroll-events/"/>
    <updated>2011-04-12T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/04/12/using-setinterval-to-handle-scroll-events</id>
    <content type="html">&lt;p&gt;I've just added a nice unobtrusive scroll to top feature to my blog, and learnt
an interesting tip in the process I thought I would share, originating from one
of the many problems Twitter has had with it's jQuery fanciness.
The scroll to top stuff isn't overly complicated - just detect when the user
has scrolled x pixels down the screen, and then show a link to go back to the
top (Which can be animated if you want) - for a nice tutorial on this, check
out_this_tutorial.
The thing is that this technique uses the scroll event (bound to window, but
can be bound to basically anything with a scrollbar). The scroll event gets
fired any time the window is scrolled - but any time the scroll amount changes
at all. What this means is that the scroll event is fired any time scroll
position changes - so if you grab the scrollbar, and pull, the scroll event is
fired every time the bar moves, not when you release the mouse.
John_Resig_reports_that_Twitter_ran_into_some_problems_with_thisÂ - they had a
function bound directly to the scroll event being fired every time anyone
scrolled (at all!). Resig has also reported a nice solution though, which I'll
pass on here. It's actually quite simple. Instead of binding a complicated
function to the scroll event, you simply set a flag variable to let something
else know that the window has been scrolled. The second piece of the solution
is a function running via setInterval - that is, a function being called on a
scheduled basis. The first task of this function is to check this flag - if it
is set, it can perform any task (Such as showing a 'Back to Top' link, and set
the flag variable back to false.Â 
The end result of this solution is that you basically have a polling function,
rather than an event-driven one. This is actually a good thing though, when it
comes to this type of event. Instead of having a complex function called every
time the window is scrolled, a function is called every quarter second or so,
and only executes if the window has been scrolledÂ - much better!
I personally used an object variable, rather than just a flag - this object was
populated with the object that was scrolled on, and I then checked if this
object was populated in my polling function (rather than just is true), and
could then use the context it provided in this function. Since then, however, I
have realized that in my case, this object will alwaysbe the window object - so
I may as well have a cheaper variable assignment and just directly refer to the
object in my polling function.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>I just found this - it's a little promotional thing that the...</title>
    <link href="http://blog.joshmcarthur.com/2011/04/12/i-just-found-this-it-s-a-little-promotional-thing-that-the/"/>
    <updated>2011-04-12T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/04/12/i-just-found-this-it-s-a-little-promotional-thing-that-the</id>
    <content type="html">&lt;p&gt;[/images/assets/www.tumblr.com/photo/1280/4533787560/1/
tumblr_ljiap6hYwQ1qd78lu.jpg]
I just found this - it's a little promotional thing that the (now non-existent)
VUW (Victoria University of Wellington IT Society) did (Well, me and Eddy) to
try and get people to join up (It worked.) - basically, I built a little IR
pen, and using a Wiimote, we managed to make a nice little giant touchscreen.
Granted, it needed calibrating often, and the correct body posture and hand
position took some finding, but it was definately a fun experiment to try out.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>Accessing controller instance variables in model (Urgh?)</title>
    <link href="http://blog.joshmcarthur.com/2011/04/12/accessing-controller-instance-variables-in-model-urgh/"/>
    <updated>2011-04-12T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/04/12/accessing-controller-instance-variables-in-model-urgh</id>
    <content type="html">&lt;p&gt;I can tell that this title alone will irritate a lot of developers out there.
It irritated me as well, until I figured out that sometimes, doing things the
'wrong' way is the best/only way. But let me get on with things.
Every now and then, you will come across a scenario where you need to access
something in the controller, from the model. This is so obviously non-MVC that
many will (should) immediately shy away from it, but let me suggest a scenario.
Let's say you have users, who should be scoped to a particular subdomain. You
would place a default_scope on the User model (with a Proc, once an issue with
default_scope is resolved), that would automatically add conditions to any
database lookup calls to restrict the found users to those belonging to the
current subdomain. The tricky bit is, of course to get this subdomain. Because
it is a default scope, you don't actually 'call' it - so that rules out passing
parameters. I've come across other suggestions as well, such as using
cattr_accessor (NO! It's shared across requests), and storing a value in
Thread.current (Relying on the application using threads in the way you expect
them to = not safe). So far though, the best hint I have seen here, although
extremely anti-doing what I am suggesting, would seem to work.Â 
Basically, the jist of this post was that you could dynamically add methods to
ActiveRecord::Base using an around_filter to access sessions, cookies, params
and the request. Now, I agree that this might be a bit too extreme - if you
really need to access the entire session or cookie hash, for example, you
probably aredoing something wrong. Something that I think isÂ suitable though,
given an appropriate situation, is to use this technique to add an 'accessor'
to ActiveRecord::Base that returns the value you need in your model - the
current subdomain for instance. This is still non-MVC, but is, I think, a far
more elegant solution that anything else I've seen suggested.&lt;/p&gt;
</content>
  </entry>
  
  <entry>
    <title>I18n ALWAYS escapes dots in chained backends :-(</title>
    <link href="http://blog.joshmcarthur.com/2011/04/08/i18n-always-escapes-dots-in-chained-backends/"/>
    <updated>2011-04-08T00:00:00+12:00</updated>
    <id>http://blog.joshmcarthur.com/2011/04/08/i18n-always-escapes-dots-in-chained-backends</id>
    <content type="html">&lt;p&gt;Just a quick tip I've come across while browsing through the comments on a
Railscast_I've_been_watching. It looks like the I18n gems that get
automatically installed with Rails 3 have a teensy bug.
When storing a translation to the backend (be it YAML, Redis, whatever), there
is an :escape option that can be passed to enable (or prevent) the key from
containing the dot character (.) (Among others, I'm sure). This seems to work
fine when dealing with a single backend, but unfortunately when you are using
chained backends (For example I am using Redis preferentially, but falling back
on YAML when necessary), the options hash that you would pass the :escape
option in is mistakenly initialized to an empty hash.
It's a simple fix - there is already a closed pull request on the issue here.
It looks like the latest stable version is only 0.50 though, so the fix isn't
going to filter through to the actual gem just yet. For now, the best option is
probably to class_eval into that particular section, or just change the file
yourself.&lt;/p&gt;
</content>
  </entry>
  
</feed>
